- 1_agent_ex.ipynb - colab

- whisper.ipynb



- whisper2.ipynb


ai_agent_work2/


langchain_env/

- 01_langchain_exam.ipynb

```jsx

```

LLM 단점

1. 최신정보를 모른다.
2. 할루에이션Hallucination

RAG(Retrieval-Augmented Generation)에서 **Chunking**은 핵심 전처리 단계입니다. 간단히 말하면:

> 🔹 Chunking은 문서를 모델이 처리하기 쉽게 작은 조각(청크, chunk) 으로 나누는 작업입니다.
> 

🔍 왜 Chunking이 중요한가?

1. **검색 정확도 향상**: 문서를 작게 나누면 더 정밀한 문맥 기반 검색이 가능함.
2. **LLM의 입력 길이 제한** 대응: GPT나 다른 LLM은 토큰 수 제한이 있기 때문에 긴 문서를 나눠야 함.
3. **응답 품질 개선**: 필요한 부분만 컨텍스트로 넣을 수 있어, 응답이 더 정확해짐.

chatbot(python) → fastapi 써서 백엔드로 이용


문서 읽어오기

청크

임베딩

vectordb
