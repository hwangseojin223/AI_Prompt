- LLM.pdf

### ncp

NCP(Naver Cloud Platform)는 AWS처럼 서버, 데이터베이스, 스토리지를 클라우드에서 **여러 사용자가 동시에 접근하고 쓸 수 있는 인프라 서비스**

### 1. **LangGraph (랭그래프)** — **AI/LLM 관련 프레임워크**

**LangGraph**는 최근 주목받는 **LLM(대형언어모델)** 기반 애플리케이션을 설계하기 위한 **상태 기계 기반 프레임워크**입니다.

LangChain과 호환되며, 에이전트나 워크플로우를 **그래프 구조**로 표현할 수 있게 해줍니다.

### 🔹 특징

- LLM의 흐름(예: 여러 도구를 사용하는 에이전트)을 상태 그래프로 구성
- 조건 분기, 루프 등 복잡한 논리 흐름 설계 가능
- LangChain, OpenAI, HuggingFace 등과 연동됨
- Python과 TypeScript 지원

workspace/ai_agent_work

ai_agent_work/

- gpt_basic.py

```python
from openai import OpenAI
from http import client

client = OpenAI(api_key=api_key)

response = client.chat.completions.create(
    model='gpt-4o',
    temperature=0.1, # 자유도
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "2022년 월드컵 우승팀은 어디야?"},
    ]
)

print(response)
print('------------------')
print(response.choices[0].message.content)

"""
temperature란?
낮은 값 (예: 0.0 ~ 0.3)
→ 더 결정적(deterministic) 결과
→ 정확하고 일관된 답변을 생성하려 할 때 유용
→ 항상 비슷한 답변을 돌려줌

높은 값 (예: 0.7 ~ 1.0)
→ 더 창의적이고 다양성 있는 출력
→ 글쓰기, 스토리 생성, 아이디어 브레인스토밍에 적합
→ 똑같은 질문에도 다양한 답변을 생성

중간 값 (예: 0.5)
→ 적당한 균형
"""
```

- gpt_basic2.ipynb

```python
from openai import OpenAI
from http import client
from dotenv import load_dotenv
import os

load_dotenv()

api_key = os.getenv('OPENAI_API_KEY')

client = OpenAI(api_key=api_key)

response = client.chat.completions.create(
    model='gpt-4o',
    temperature=0.1, # 자유도
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "2026년 월드컵 개최 국가는 어디야?"},
    ]
)

print(response)
print('------------------')
print(response.choices[0].message.content)
```

- multi_exam.ipynb

```python
from openai import OpenAI
from http import client
from dotenv import load_dotenv
import os

load_dotenv()

api_key = os.getenv('OPENAI_API_KEY')

client = OpenAI(api_key=api_key)

def get_ai_response(messages):
    response = client.chat.completions.create(
        model='gpt-4o-mini',
        temperature=0.9, # 자유도
        messages=messages,
    )
    return response.choices[0].message.content

messages=[
    {"role": "system", "content": "너는 사용자를 도와주는 상담사야."},
]
while True:
    user_input = input('사용자: ')
    
    if user_input == 'exit':
        break
    
    messages.append({"role": "user", "content": user_input})
    ai_response = get_ai_response(messages)
    messages.append({"role": "assistant", "content": ai_response})
    print('AI: ' + ai_response)
```

- summary.ipynb
```
from openai import OpenAI
from http import client
from dotenv import load_dotenv
import os

load_dotenv()

api_key = os.getenv('OPENAI_API_KEY')

client = OpenAI(api_key=api_key)

def summarize_txt(file_path: str):
    client = OpenAI(api_key=api_key)
    
    with open(file_path, 'r', encoding='utf-8') as f:
        txt = f.read()
        
    # 요약을 위한 시스템 프롬프트를 생성
    system_prompt = f'''
    너는 다음 글을 요약하는 봇이다. 아래 글을 읽고, 저자의 문제 인식과 주장을 파악하고, 주요 내용을 요약하라.
    
    작성해야 하는 포맷은 다음과 같다.
    
    # 제목
    
    ## 저자의 문제 인식 및 주장 (15문장 이내)
    
    ## 저자 소개
    
    ====================================== 이하 텍스트 =====================================
    {txt}
    '''
    
    print(system_prompt)
    print('===================================================================')
    
    response = client.chat.completions.create(
        model='gpt-4o-mini',
        temperature=0.1, # 자유도
        messages=[
            {"role": "system", "content": system_prompt}
        ],
    )
    
    return response.choices[0].message.content
    
    if __name__ == '__main__':
    file_path = './output/과정기반 작물모형을 이용한 웹 기반 밀 재배관리 의사결정 지원시스템 설계 및 구축_with_preprocessing.txt'
    
    summary = summarize_txt(file_path)
    print(summary)
    
    with open('./output/summary.txt', 'w', encoding='utf-8') as f:
        f.write(summary)
```
